{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Department1': <tf.Tensor: shape=(), dtype=int64, numpy=78>, 'Department2': <tf.Tensor: shape=(), dtype=string, numpy=b'Science'>}\n",
      "{'Department1': <tf.Tensor: shape=(), dtype=int64, numpy=16>, 'Department2': <tf.Tensor: shape=(), dtype=string, numpy=b'Maths'>}\n",
      "{'Department1': <tf.Tensor: shape=(), dtype=int64, numpy=89>, 'Department2': <tf.Tensor: shape=(), dtype=string, numpy=b'Biology'>}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    " \n",
    "df = pd.DataFrame({'Department1':[78,16,89],\n",
    "                   'Department2': ['Science','Maths','Biology']})\n",
    " \n",
    "df\n",
    "new_df_val = tf.data.Dataset.from_tensor_slices(dict(df))\n",
    "new_df_val \n",
    "for i in new_df_val .take(3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Department1': <tf.Tensor: shape=(), dtype=int64, numpy=178>, 'Department2': <tf.Tensor: shape=(), dtype=string, numpy=b'Chemistry'>}\n",
      "{'Department1': <tf.Tensor: shape=(), dtype=int64, numpy=965>, 'Department2': <tf.Tensor: shape=(), dtype=string, numpy=b'Maths'>}\n",
      "{'Department1': <tf.Tensor: shape=(), dtype=int64, numpy=156>, 'Department2': <tf.Tensor: shape=(), dtype=string, numpy=b'Biology'>}\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'Department1':[178,965,156],\n",
    "                   'Department2': ['Chemistry','Maths','Biology']})\n",
    " \n",
    "df\n",
    "new_df_val = tf.data.Dataset.from_tensor_slices(dict(df))\n",
    "new_df_val \n",
    "for i in new_df_val .take(3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request as rq\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyarrow as pa # this is needed for the parquet file\n",
    "import numpy as np\n",
    "import ipywidgets\n",
    "from ipywidgets import widgets\n",
    "from ipywidgets import interact, interactive, fixed, VBox\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the Dublin bus gz files \n",
    "def load_Files(direc, files, comtype):\n",
    "    columns = ['Timestamp', 'LineID', 'Direction', 'JourneyPatternID', 'TimeFrame', 'VehicleJourneyID', 'Operator', 'Congestion', 'LonWGS84', 'LatWGS84', 'Delay', 'BlockID', 'VehicleID', 'StopID', 'AtStop']\n",
    "    for f in files:\n",
    "        print(f)\n",
    "        yield pd.read_csv(direc + f, compression=comtype, delimiter=',', header=0, names=columns, parse_dates=True, low_memory=True)\n",
    "\n",
    "def crackit_open(busFile):\n",
    "    import zipfile as zip\n",
    "    # Zip creates its own folders - no need to check for folder existence\n",
    "    with zip.ZipFile(busFile,  mode='r') as arc: \n",
    "        arc.extractall('./Data/Bus/Gz/')  \n",
    "    files = os.listdir('./Data/Bus/Gz/')\n",
    "    DBfiles = [f for f in files if f.endswith('.gz')]\n",
    "    df = pd.concat(load_Files('./Data/Bus/Gz/', DBfiles, 'gzip'), copy = False)\n",
    "    return df\n",
    "\n",
    "def shapiro_test(x):\n",
    "    p_val = stats.shapiro(x)[1]\n",
    "    status = 'passed'\n",
    "    color = 'blue'\n",
    "    if p_val < 0.05:\n",
    "        status = 'failed'\n",
    "        color = 'red'\n",
    "    return status, color, p_val\n",
    "\n",
    "def custom_scatterplot(df1, col1=''):\n",
    "    df1 = df1[df1[\"LineID\"]==col1]\n",
    "    f = plt.figure()\n",
    "    f, ax = plt.subplots(figsize=(11.5, 11.5))\n",
    "    ax = f.add_subplot(projection='3d')\n",
    "    ax.scatter(df1['LonWGS84'], df1['LatWGS84'], df1['Hour'], alpha=0.6, color=df1['Colour'])\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_zlabel('Hour')\n",
    "    dcol = str(col1)\n",
    "    plt.savefig('./Images/Img_' + dcol + '_Longitude_Latitude_Hour.svg')\n",
    "    df1.to_parquet('./Data/Bus/LineID_' + dcol + '.parquet')\n",
    "    \n",
    "    \n",
    "def custom_barplot(df1, col1=''):\n",
    "    if len(df1[col1]) > 5000: # added this to the function because of warnings about the size of data being used with shapiro test\n",
    "            sampleSize = 5000\n",
    "    else:\n",
    "        sampleSize = len(df1[col1])\n",
    "    df1 = df1.sample(sampleSize) #shapiro test is unreliable over 5000 https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test and performance reasons\n",
    "    f, ax = plt.subplots(2,2, figsize=(11.5, 11.5))\n",
    "    ax = ax.reshape(-1)\n",
    "    df1[col1].plot(ax=ax[0], kind='hist')\n",
    "    ax[0].set_title('Histogram of {}'.format(col1))\n",
    "    df1[col1].plot(ax=ax[1], kind='kde')\n",
    "    ax[1].set_title('Density Plot of {}'.format(col1))\n",
    "    ax3 = plt.subplot(223)\n",
    "    stats.probplot(df[col1], plot=plt)\n",
    "    ax[2].set_title('QQ Plot of {}'.format(col1))\n",
    "    df1[col1].plot(ax=ax[3], kind='box')\n",
    "    ax[3].set_title('Box Plot of {}'.format(col1))\n",
    "    status, color, p_val = shapiro_test(df1[col1]) \n",
    "    f.suptitle('Normality test for {} {} (p_value = {})'.format(col1, status, p_val), color=color, fontsize=12)\n",
    "\n",
    "def num_missing(x):\n",
    "    return len(x.index)-x.count()\n",
    "\n",
    "def num_unique(x):\n",
    "    return len(np.unique(x))\n",
    "\n",
    "def load_csv_Files(direc, files):\n",
    "\n",
    "    for f in files:\n",
    "        # need to get number of rows to skip \n",
    "        temp=pd.read_csv(direc + f,sep='^',header=None,prefix='X')\n",
    "        temp2=temp.X0.str.split(',',expand=True)\n",
    "        del temp['X0']\n",
    "        temp=pd.concat([temp,temp2],axis=1)\n",
    "        cols = list(range(0,temp.shape[1]))\n",
    "\n",
    "        print(f)\n",
    "        yield pd.read_csv(direc + f,  delimiter=',', header=0,  parse_dates=True, low_memory=True, skiprows=14, usecols=cols, na_values='NAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folder exists\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('./Data'):\n",
    "    print('Data folder exists')\n",
    "\n",
    "if os.path.exists('./Data/Bus'):\n",
    "    print('Bus Data folder exists')\n",
    "else:\n",
    "    os.makedirs('./Data/Bus')\n",
    "\n",
    "if os.path.exists('./Data/MetEirrean/'):\n",
    "    print('Weather data folder exists')\n",
    "else:\n",
    "    os.makedirs('./Data/MetEirrean/')\n",
    "\n",
    "if os.path.exists('./Zips/MetEirrean'):\n",
    "    print('Weather folder exisits')\n",
    "else:\n",
    "    os.makedirs('./Zips/MetEirrean/')\n",
    "\n",
    "if os.path.exists('./Images/'):\n",
    "    print('Images folder exists')\n",
    "else:\n",
    "    os.makedirs('./Images/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquest file exists, means the Bus data has been downloaded already \n"
     ]
    }
   ],
   "source": [
    "# Check parquet file existence before downloading - iof starting from afresh this takes a long time\n",
    "if os.path.exists('./Data/CleanedBusData.parquet'):\n",
    "    print(\"Parquest file exists, means the Bus data has been downloaded already \")\n",
    "    df = pd.read_parquet('./Data/CleanedBusData.parquet')\n",
    "    if os.path.exists('./Data/WeatherandBusData.parquet'):\n",
    "        print('Weather and bus data combined exists')\n",
    "        mdf = pd.read_parquet('./Data/WeatherandBusData.parquet')\n",
    "elif os.path.exists('./Zips/Bus/DublinBusdata.zip'):\n",
    "    print(\"Zip file exists, we have already downloaded the Dublin Bus Zip data, crack it open\")\n",
    "    df = crackit_open('./Zips/Bus/DublinBusdata.zip')\n",
    "else:\n",
    "    os.makedirs('./Zips/Bus/', exist_ok = True)\n",
    "    url = \"https://opendata.dublincity.ie/TrafficOpenData/sir010113-310113.zip\"\n",
    "    busFile = rq.urlretrieve(url, './Zips/Bus/DublinBusdata.zip' )  \n",
    "    df = crackit_open('./Zips/Bus/DublinBusdata.zip')\n",
    "\n",
    "df = df.sample(20000000)\n",
    "### Read the Bus data in to a Pandas dataframe - done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <td>19998897.0</td>\n",
       "      <td>1.358318e+15</td>\n",
       "      <td>7.395001e+11</td>\n",
       "      <td>1.356998e+15</td>\n",
       "      <td>1.357679e+15</td>\n",
       "      <td>1.358327e+15</td>\n",
       "      <td>1.358955e+15</td>\n",
       "      <td>1.359633e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LineID</th>\n",
       "      <td>19998897.0</td>\n",
       "      <td>7.796954e+01</td>\n",
       "      <td>1.146472e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>7.470000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VehicleJourneyID</th>\n",
       "      <td>19998897.0</td>\n",
       "      <td>9.415629e+03</td>\n",
       "      <td>6.159182e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.535000e+03</td>\n",
       "      <td>4.718000e+03</td>\n",
       "      <td>6.769000e+03</td>\n",
       "      <td>9.998560e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Congestion</th>\n",
       "      <td>19998897.0</td>\n",
       "      <td>1.164869e-02</td>\n",
       "      <td>1.072987e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LonWGS84</th>\n",
       "      <td>19998897.0</td>\n",
       "      <td>-6.272790e+00</td>\n",
       "      <td>8.388212e-02</td>\n",
       "      <td>-6.617434e+00</td>\n",
       "      <td>-6.308630e+00</td>\n",
       "      <td>-6.261595e+00</td>\n",
       "      <td>-6.233166e+00</td>\n",
       "      <td>-6.052917e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LatWGS84</th>\n",
       "      <td>19998897.0</td>\n",
       "      <td>5.334513e+01</td>\n",
       "      <td>5.486668e-02</td>\n",
       "      <td>5.306802e+01</td>\n",
       "      <td>5.332004e+01</td>\n",
       "      <td>5.334645e+01</td>\n",
       "      <td>5.337532e+01</td>\n",
       "      <td>5.360870e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delay</th>\n",
       "      <td>19998897.0</td>\n",
       "      <td>-2.814680e+01</td>\n",
       "      <td>4.734957e+02</td>\n",
       "      <td>-1.504500e+04</td>\n",
       "      <td>-2.090000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.040000e+02</td>\n",
       "      <td>1.161220e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlockID</th>\n",
       "      <td>19998897.0</td>\n",
       "      <td>1.092300e+05</td>\n",
       "      <td>1.921073e+05</td>\n",
       "      <td>3.900000e+02</td>\n",
       "      <td>1.602000e+04</td>\n",
       "      <td>4.020500e+04</td>\n",
       "      <td>8.400400e+04</td>\n",
       "      <td>8.350020e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VehicleID</th>\n",
       "      <td>19998897.0</td>\n",
       "      <td>3.542959e+04</td>\n",
       "      <td>3.281788e+03</td>\n",
       "      <td>2.804700e+04</td>\n",
       "      <td>3.330800e+04</td>\n",
       "      <td>3.352400e+04</td>\n",
       "      <td>3.802500e+04</td>\n",
       "      <td>4.307800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AtStop</th>\n",
       "      <td>19998897.0</td>\n",
       "      <td>2.334375e-01</td>\n",
       "      <td>4.230183e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <td>19998897.0</td>\n",
       "      <td>1.567217e+01</td>\n",
       "      <td>8.563570e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hour</th>\n",
       "      <td>19998897.0</td>\n",
       "      <td>1.388665e+01</td>\n",
       "      <td>4.921978e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>2.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minute</th>\n",
       "      <td>19998897.0</td>\n",
       "      <td>2.946816e+01</td>\n",
       "      <td>1.728921e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>5.900000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count          mean           std           min  \\\n",
       "Timestamp         19998897.0  1.358318e+15  7.395001e+11  1.356998e+15   \n",
       "LineID            19998897.0  7.796954e+01  1.146472e+02  1.000000e+00   \n",
       "VehicleJourneyID  19998897.0  9.415629e+03  6.159182e+04  1.000000e+00   \n",
       "Congestion        19998897.0  1.164869e-02  1.072987e-01  0.000000e+00   \n",
       "LonWGS84          19998897.0 -6.272790e+00  8.388212e-02 -6.617434e+00   \n",
       "LatWGS84          19998897.0  5.334513e+01  5.486668e-02  5.306802e+01   \n",
       "Delay             19998897.0 -2.814680e+01  4.734957e+02 -1.504500e+04   \n",
       "BlockID           19998897.0  1.092300e+05  1.921073e+05  3.900000e+02   \n",
       "VehicleID         19998897.0  3.542959e+04  3.281788e+03  2.804700e+04   \n",
       "AtStop            19998897.0  2.334375e-01  4.230183e-01  0.000000e+00   \n",
       "Day               19998897.0  1.567217e+01  8.563570e+00  1.000000e+00   \n",
       "Hour              19998897.0  1.388665e+01  4.921978e+00  0.000000e+00   \n",
       "Minute            19998897.0  2.946816e+01  1.728921e+01  0.000000e+00   \n",
       "\n",
       "                           25%           50%           75%           max  \n",
       "Timestamp         1.357679e+15  1.358327e+15  1.358955e+15  1.359633e+15  \n",
       "LineID            2.500000e+01  4.000000e+01  8.300000e+01  7.470000e+02  \n",
       "VehicleJourneyID  2.535000e+03  4.718000e+03  6.769000e+03  9.998560e+05  \n",
       "Congestion        0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00  \n",
       "LonWGS84         -6.308630e+00 -6.261595e+00 -6.233166e+00 -6.052917e+00  \n",
       "LatWGS84          5.332004e+01  5.334645e+01  5.337532e+01  5.360870e+01  \n",
       "Delay            -2.090000e+02  0.000000e+00  1.040000e+02  1.161220e+05  \n",
       "BlockID           1.602000e+04  4.020500e+04  8.400400e+04  8.350020e+05  \n",
       "VehicleID         3.330800e+04  3.352400e+04  3.802500e+04  4.307800e+04  \n",
       "AtStop            0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00  \n",
       "Day               8.000000e+00  1.600000e+01  2.300000e+01  3.100000e+01  \n",
       "Hour              1.000000e+01  1.400000e+01  1.800000e+01  2.300000e+01  \n",
       "Minute            1.500000e+01  2.900000e+01  4.400000e+01  5.900000e+01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LineID</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VehicleJourneyID</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Operator</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Congestion</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LonWGS84</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LatWGS84</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delay</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlockID</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VehicleID</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AtStop</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hour</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minute</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  missing\n",
       "Timestamp               0\n",
       "LineID                  0\n",
       "VehicleJourneyID        0\n",
       "Operator                0\n",
       "Congestion              0\n",
       "LonWGS84                0\n",
       "LatWGS84                0\n",
       "Delay                   0\n",
       "BlockID                 0\n",
       "VehicleID               0\n",
       "AtStop                  0\n",
       "datetime                0\n",
       "Time                    0\n",
       "Day                     0\n",
       "Hour                    0\n",
       "Minute                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'Direction' in df.columns:\n",
    "    df = df.drop(['Direction'], axis='columns')\n",
    "if 'TimeFrame' in df.columns:\n",
    "    df = df.drop(['TimeFrame'], axis='columns')\n",
    "\"\"\" if {'VehicleJourneyID', 'JourneyPatternID'}.issubset(df.columns):  \n",
    "    df['VehicleJourneyID'] = df['JourneyPatternID'] + '_' + df['VehicleJourneyID'].astype('str')\n",
    "    df = df.drop(['JourneyPatternID','VehicleJourneyID'], axis='columns') \"\"\"\n",
    "\n",
    "df = df.dropna() \n",
    "df = df.drop_duplicates()\n",
    "\n",
    "temp_df = df.describe().T\n",
    "missing_df = pd.DataFrame(df.apply(num_missing, axis=0)) \n",
    "missing_df.columns = ['missing']  # type: ignore\n",
    "\n",
    "display(temp_df)\n",
    "\n",
    "display(missing_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 19998897 Rows and 16 columns\n",
      "The types of columns are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timestamp                    int64\n",
       "LineID                     float64\n",
       "VehicleJourneyID             int64\n",
       "Operator                    object\n",
       "Congestion                   int64\n",
       "LonWGS84                   float64\n",
       "LatWGS84                   float64\n",
       "Delay                        int64\n",
       "BlockID                      int64\n",
       "VehicleID                    int64\n",
       "AtStop                       int64\n",
       "datetime            datetime64[ns]\n",
       "Time                        object\n",
       "Day                          int64\n",
       "Hour                         int64\n",
       "Minute                       int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print ('The data has {} Rows and {} columns'.format(df.shape[0],df.shape[1]))\n",
    "print(\"The types of columns are:\")\n",
    "display(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['datetime'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp             int64\n",
       "LineID              float64\n",
       "VehicleJourneyID      int64\n",
       "Operator             object\n",
       "Congestion            int64\n",
       "LonWGS84            float64\n",
       "LatWGS84            float64\n",
       "Delay                 int64\n",
       "BlockID               int64\n",
       "VehicleID             int64\n",
       "AtStop                int64\n",
       "Time                 object\n",
       "Day                   int64\n",
       "Hour                  int64\n",
       "Minute                int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'Timestamp': 'float64', 'VehicleJourneyID': 'float64',  'Congestion': 'float64', 'Delay': 'float64', 'BlockID': 'float64', 'VehicleID': 'float64',  'AtStop': 'float64', 'Day': 'float64', 'Hour':'float64', 'Minute': 'float64' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp           float64\n",
       "LineID              float64\n",
       "VehicleJourneyID    float64\n",
       "Operator             object\n",
       "Congestion          float64\n",
       "LonWGS84            float64\n",
       "LatWGS84            float64\n",
       "Delay               float64\n",
       "BlockID             float64\n",
       "VehicleID           float64\n",
       "AtStop              float64\n",
       "Time                 object\n",
       "Day                 float64\n",
       "Hour                float64\n",
       "Minute              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Program Files\\Python39\\tf\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m           \u001b[0mspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_fallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python39\\tf\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[1;34m(element, use_fallback)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m   raise TypeError(\"Could not build a `TypeSpec` for {} with type {}\".format(\n\u001b[0m\u001b[0;32m    488\u001b[0m       \u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not build a `TypeSpec` for             Timestamp  LineID  VehicleJourneyID Operator  Congestion  \\\n386289   1.357993e+15    39.0           10028.0       PO         0.0   \n203938   1.358496e+15    68.0            1694.0       CD         0.0   \n563196   1.357125e+15    66.0            2465.0       PO         0.0   \n1398997  1.357845e+15    13.0            3392.0       CD         0.0   \n1097202  1.358528e+15    16.0            4727.0       SL         0.0   \n...               ...     ...               ...      ...         ...   \n507107   1.357296e+15     1.0            4627.0       RD         0.0   \n588651   1.359373e+15    31.0            6994.0       CF         0.0   \n492096   1.357123e+15   122.0            1424.0       PO         0.0   \n947848   1.357917e+15    42.0            7219.0       CF         0.0   \n1309405  1.357755e+15     9.0            3621.0       PO         0.0   \n\n         LonWGS84   LatWGS84  Delay   BlockID  VehicleID  AtStop      Time  \\\n386289  -6.435270  53.401623  -35.0   39013.0    40001.0     1.0  12:08:26   \n203938  -6.457979  53.319115  229.0   68005.0    38060.0     0.0  08:04:04   \n563196  -6.277333  53.357533 -561.0  817023.0    36044.0     1.0  11:15:08   \n1398997 -6.358805  53.321270 -974.0   13008.0    33298.0     0.0  19:10:04   \n1097202 -6.265387  53.353470 -501.0   16005.0    33428.0     0.0  16:46:07   \n...           ...        ...    ...       ...        ...     ...       ...   \n507107  -6.226732  53.341820 -490.0    1002.0    43077.0     1.0  10:35:51   \n588651  -6.193755  53.375637 -475.0   31010.0    38012.0     0.0  11:38:05   \n492096  -6.321320  53.330437 -868.0   12215.0    33049.0     0.0  10:30:52   \n947848  -6.257850  53.349651  -91.0   42001.0    38088.0     1.0  15:10:29   \n1309405 -6.272670  53.360435 -285.0    9006.0    33367.0     0.0  18:13:33   \n\n          Day  Hour  Minute  \n386289   12.0  12.0     8.0  \n203938   18.0   8.0     4.0  \n563196    2.0  11.0    15.0  \n1398997  10.0  19.0    10.0  \n1097202  18.0  16.0    46.0  \n...       ...   ...     ...  \n507107    4.0  10.0    35.0  \n588651   28.0  11.0    38.0  \n492096    2.0  10.0    30.0  \n947848   11.0  15.0    10.0  \n1309405   9.0  18.0    13.0  \n\n[19998897 rows x 15 columns] with type DataFrame",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1708\\75361276.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_df_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Program Files\\Python39\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \"\"\"\n\u001b[1;32m--> 814\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m   \u001b[1;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python39\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, element, is_files, name)\u001b[0m\n\u001b[0;32m   4706\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_files\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4707\u001b[0m     \u001b[1;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4708\u001b[1;33m     \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4709\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4710\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python39\\tf\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;31m# the value. As a fallback try converting the value to a tensor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         normalized_components.append(\n\u001b[1;32m--> 108\u001b[1;33m             ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[0;32m    109\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensorSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python39\\tf\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python39\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python39\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    341\u001b[0m                                          as_ref=False):\n\u001b[0;32m    342\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python39\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \"\"\"\n\u001b[1;32m--> 267\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    268\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python39\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python39\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m   \u001b[1;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python39\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "new_df_val = tf.data.Dataset.from_tensor_slices(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c347c8f9a7ef94e4c9e03b4513be7835ed18f45b99a2a817fb579f408b867b16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
